# 机器学习

## Weka
### 线性回归


### 随机森林


#### 主要用途
+ 分类、回归

#### 大致实现
+ 从原始训练集中使用Bootstraping发放随机有放回采样选出m个样本，共进行n_tree次采样，生成n_tree个训练集
+ 对于n_tree个训练集，我们分别训练n_tree个决策树模型
+ 对于单个决策树模型，假设训练样本的个数为n，那么每次分裂时根据信息增益/信息增益比/基尼指数选择最好的特征进行分裂
+ 每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。在决策时的分裂过程中不需要剪枝。
+ 将生成的多颗决策树组成随机森林。对于分类问题，按多棵树分类器投票决定最终分类结果；对于回归问题，由多棵树预测值的均值决定最终的预测结果。

#### 优点
+ 具有极高的准确率
+ 随机性的引入，使得随机森林不容易过拟合
+ 随机性的引入，使得随机森林有很好的抗噪声能力
+ 能处理很高维度的数据，并且不用做特征选择
+ 既能处理离散型数据，也能处理连续型数据，数据集无需规范化
+ 训练速度快，可以得到变量重要性的排序
+ 容易实现并行化

#### 缺点
+ 当随机森林中的决策树个数很多时，训练时需要的空间和时间会较大
+ 随机森林模型中有很多不好解释的地方，有点算个黑盒模型
